# README: Система Распознавания Голосовых Команд

## Метрики
#### ЦП: Intel(R) Core(TM) i5-10400F CPU @ 2.90GHz
#### ОЗУ: 16 Гб
| Метрики     | Значение   |
|-------------|------------|
| WER         | 0.50       |
| F1          | 1.00       |
| CPU Latency | 55 - 91 мс |
| RAM         | 262.87 MB  |

## Обзор
Этот проект реализует **систему распознавания голосовых команд**, созданную с использованием **PyTorch**, **Torchaudio** и других библиотек. Модель предназначена для распознавания и классификации заранее определённого набора команд, связанных с железнодорожными операциями, на основе аудиозаписей. В системе также реализовано снижение шума и оценка производительности модели с помощью таких метрик, как **Word Error Rate (WER)** и **F1 Score**.

## Особенности
1. **Снижение шума**: Удаление фонового шума из аудиозаписей с использованием библиотеки `noisereduce`.
2. **Преобразование в мел-спектрограмму**: Преобразование аудио в мел-спектрограммы для подачи на вход модели.
3. **Распознавание команд**: Использование GRU-нейронной сети для классификации голосовых команд.
4. **Извлечение атрибутов команд**: Извлечение числовых атрибутов из транскрибированных команд (в разработке).
5. **Метрики производительности**: Оценка производительности с использованием WER, задержки ЦП, потребления памяти и F1 Score.

## Требования
### Библиотеки:
- Python 3.10+
- PyTorch
- Torchaudio
- Noisereduce
- Jiwer
- Scikit-learn
- Psutil

Для установки необходимых пакетов:
```bash
pip install torch torchaudio noisereduce jiwer scikit-learn psutil
```

## Команды и Метки
Система поддерживает набор из **22 предопределённых команд**, связанных с железнодорожными операциями, такими как "осадить на (количество) вагон" и "остановка". Каждой команде соответствует уникальная метка.

```python
COMMANDS = {
    "отказ": 0,
    "отмена": 1,
    "подтверждение": 2,
    ...
    "отпустить": 22,
}
```

## Архитектура Модели
Модель использует **GRU (Gated Recurrent Unit)** нейронную сеть со следующей структурой:
- Входной слой: Мел-спектрограммы.
- Скрытый слой: GRU с 64 скрытыми нейронами.
- Выходной слой: Полносвязный слой с 22 выходными классами (для каждой команды).

```python
class SpeechRecognitionModel(nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super(SpeechRecognitionModel, self).__init__()
        self.gru = nn.GRU(input_size, hidden_size, batch_first=True)
        self.fc = nn.Linear(hidden_size, output_size)
        
    def forward(self, x):
        gru_out, _ = self.gru(x)
        last_hidden_state = gru_out[:, -1, :]
        output = self.fc(last_hidden_state)
        return output
```

## Шаги Предварительной Обработки
1. **Снижение Шума**: Функция `denoise_audio` обрабатывает аудиофайлы, снижает шум и сохраняет очищенные аудиофайлы.
   
2. **Преобразование в Мел-Спектрограмму**: Очищенное аудио преобразуется в мел-спектрограммы с использованием `torchaudio.transforms.MelSpectrogram`.

## Как Запустить Систему
1. **Загрузка Модели**: Загрузите предобученную модель из файла `.pth` с помощью функции `load_model`.
2. **Обработка Аудио**: Вызовите функцию `process_audio_command` для предсказания команды в аудиофайле.
3. **Вывод в JSON**: Результат (предсказанная команда, метка и извлечённые атрибуты) сохраняется в файл `.json`.

### Пример Рабочего Процесса:
```python
if __name__ == "__main__":
    # Загрузка модели
    loaded_model = load_model('speech_recognition_model2.pth')

    # Обработка аудиофайла и сохранение результата
    audio_file_path = 'path/to/audio.wav'
    result = process_audio_command(audio_file_path, loaded_model)

    # Сохранение результата в JSON
    with open('commands.json', 'w') as f:
        json.dump(result, f, ensure_ascii=False, indent=4)
```

## Оценка Производительности
- **Измерение Задержки (Latency)**: Время, затраченное на обработку аудио и предсказание, записывается в миллисекундах.
- **Использование Памяти**: Потребление памяти рассчитывается с использованием библиотеки `psutil`.
- **Word Error Rate (WER)**: Сравнивается транскрибированная команда с эталоном.
- **F1 Score**: Оценивается точность предсказаний модели.

```python
# Задержка ЦП
start = time.time()
# Вызов предсказания
print(f"Задержка: {(time.time() - start) * 1000:.2f} мс")

# Использование памяти
memory_usage = psutil.Process(os.getpid()).memory_info().rss
print(f"Используемая память: {memory_usage / (1024 ** 2):.2f} MB")

# WER (Word Error Rate)
ground_truth = "осадить на пять вагонов"
hypothesis = result["text"]
wer = jiwer.wer(ground_truth, hypothesis)
print(f"Word Error Rate (WER): {wer:.2f}")

# F1 Score
y_true = [4]  # Истинная метка
y_pred = [result["label"]]  # Предсказанная метка
f1 = f1_score(y_true, y_pred, average='macro')
print(f"F1 Score: {f1:.2f}")
```

## Текущие Проблемы и Будущие Задачи
- **Низкая Точность Прогнозов**:
- **Извлечение Атрибутов**: Динамическое извлечение числовых значений (например, "пять" -> 5) из транскрипций пока не полностью реализовано.

## Структура Проекта
```
├── luga/
│   └── 02_11_2023/
│       └── 2023_11_02__10_45_36.wav
├── outputs/
│   └── denoised_audio.wav
├── speech_recognition_model2.pth
├── commands.json
└── main.py
```


## Контакты
Если у вас возникли вопросы, свяжитесь с разработчиком проекта.

---

